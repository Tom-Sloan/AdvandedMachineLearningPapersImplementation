{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C. H. Lampert, et al.</td>\n",
       "      <td>Attribute-based classification for zero-shot v...</td>\n",
       "      <td>T-PAMI</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y. Xian, et al.</td>\n",
       "      <td>Latent embeddings for zero-shot classification</td>\n",
       "      <td>CVPR</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E. Kodirov, et al.</td>\n",
       "      <td>Semantic Autoencoder for Zero-Shot Learning</td>\n",
       "      <td>CVPR</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y. Xian, et al.</td>\n",
       "      <td>Feature Generating Networks for Zero-Shot Lear...</td>\n",
       "      <td>CVPR</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J. Snell, K. Swersky, and R. Zemel</td>\n",
       "      <td>Prototypical networks for few-shot learning</td>\n",
       "      <td>NIPS</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Author Name  \\\n",
       "0               C. H. Lampert, et al.   \n",
       "1                     Y. Xian, et al.   \n",
       "2                  E. Kodirov, et al.   \n",
       "3                     Y. Xian, et al.   \n",
       "4  J. Snell, K. Swersky, and R. Zemel   \n",
       "\n",
       "                                          Paper Name Publisher  Year  \n",
       "0  Attribute-based classification for zero-shot v...    T-PAMI  2014  \n",
       "1     Latent embeddings for zero-shot classification      CVPR  2016  \n",
       "2        Semantic Autoencoder for Zero-Shot Learning      CVPR  2017  \n",
       "3  Feature Generating Networks for Zero-Shot Lear...      CVPR  2018  \n",
       "4        Prototypical networks for few-shot learning      NIPS  2017  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "paper_df = pd.read_csv('paper_list.csv')\n",
    "\n",
    "# Display the DataFrame (optional, can be removed if not needed)\n",
    "paper_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1703.03400v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Prototypical networks for few-shot learning.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1606.04080v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Matching Networks for One Shot Learning.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Prototypical networks for few-shot learning.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1711.06025v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Learning to Compare: Relation Network for Few-Shot Learning.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1710.10196v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Image-to-image translation with conditional adversarial networks.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1711.09020v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/A style-based generator architecture for generative adversarial networks.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1511.06335v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Unsupervised deep embedding for clustering analysis.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2203.05794v1.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/BERTopic: Neural topic modeling with a class-based TF-IDF procedure.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1606.09282v3-2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Learning without Forgetting.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Unsupervised_Visual_Domain_Adaptation_Using_Subspace_Alignment.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Unsupervised Visual Domain Adaptation Using Subspace Alignment.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1711.03213v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/CyCADA: Cycle-Consistent Adversarial Domain Adaptation.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2002.05709v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/A Simple Framework for Contrastive Learning of Visual Representations.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1911.05722v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Momentum Contrast for Unsupervised Visual Representation Learning.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2006.07733v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2006.09882v5.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Unsupervised Learning of Visual Features by Contrasting Cluster Assignments.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1602.04938v3.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Why Should I Trust You?: Explaining the Predictions of Any Classifier.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1705.07874v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/A Unified Approach to Interpreting Model Predictions.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1711.11279v5.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV).pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1710.04806v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/1806.10574v5.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/This Looks Like That: Deep Learning for Interpretable Image Recognition.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/language_understanding_paper.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Improving language understanding by generative pre-training.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2205.11916v4.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Large language models are zero-shot reasoners.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2103.00020v1.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Learning transferable visual models from natural language supervision.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2006.11239v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Denoising diffusion probabilistic models.pdf.\n",
      "Renamed /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/2211.09800v2.pdf to /Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs/Instructpix2pix: Learning to follow image editing instructions.pdf.\n",
      "No duplicate used papers found.\n",
      "Duplicate Unused Papers: {''}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Used Papers</th>\n",
       "      <th>Unused Papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prototypical networks for few-shot learning</td>\n",
       "      <td>Attribute-based classification for zero-shot v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matching Networks for One Shot Learning</td>\n",
       "      <td>Latent embeddings for zero-shot classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model-Agnostic Meta-Learning for Fast Adaptati...</td>\n",
       "      <td>Semantic Autoencoder for Zero-Shot Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learning to Compare: Relation Network for Few-...</td>\n",
       "      <td>Feature Generating Networks for Zero-Shot Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image-to-image translation with conditional ad...</td>\n",
       "      <td>Unpaired image-to-image translation using cycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A style-based generator architecture for gener...</td>\n",
       "      <td>Progressive Growing of GANs for Improved Quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unsupervised deep embedding for clustering ana...</td>\n",
       "      <td>Stargan: Unified generative adversarial networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BERTopic: Neural topic modeling with a class-b...</td>\n",
       "      <td>Towards k-means-friendly spaces: Simultaneous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Learning without Forgetting</td>\n",
       "      <td>Spectralnet: Spectral clustering using deep ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unsupervised Visual Domain Adaptation Using Su...</td>\n",
       "      <td>Grad-cam: Visual explanations from deep networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CyCADA: Cycle-Consistent Adversarial Domain Ad...</td>\n",
       "      <td>Anchors: High-Precision Model-Agnostic Explana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Simple Framework for Contrastive Learning of...</td>\n",
       "      <td>Bert: Pre-training of deep bidirectional trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Momentum Contrast for Unsupervised Visual Repr...</td>\n",
       "      <td>Prefix-tuning: Optimizing continuous prompts f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bootstrap Your Own Latent: A New Approach to S...</td>\n",
       "      <td>Lora: Low-rank adaptation of large language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Unsupervised Learning of Visual Features by Co...</td>\n",
       "      <td>An Image is Worth 16x16 Words: Transformers fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why Should I Trust You?: Explaining the Predic...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A Unified Approach to Interpreting Model Predi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Interpretability Beyond Feature Attribution: Q...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Deep Learning for Case-Based Reasoning through...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This Looks Like That: Deep Learning for Interp...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Improving language understanding by generative...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Large language models are zero-shot reasoners</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Learning transferable visual models from natur...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Denoising diffusion probabilistic models</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Instructpix2pix: Learning to follow image edit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Used Papers  \\\n",
       "0         Prototypical networks for few-shot learning   \n",
       "1             Matching Networks for One Shot Learning   \n",
       "2   Model-Agnostic Meta-Learning for Fast Adaptati...   \n",
       "3   Learning to Compare: Relation Network for Few-...   \n",
       "4   Image-to-image translation with conditional ad...   \n",
       "5   A style-based generator architecture for gener...   \n",
       "6   Unsupervised deep embedding for clustering ana...   \n",
       "7   BERTopic: Neural topic modeling with a class-b...   \n",
       "8                         Learning without Forgetting   \n",
       "9   Unsupervised Visual Domain Adaptation Using Su...   \n",
       "10  CyCADA: Cycle-Consistent Adversarial Domain Ad...   \n",
       "11  A Simple Framework for Contrastive Learning of...   \n",
       "12  Momentum Contrast for Unsupervised Visual Repr...   \n",
       "13  Bootstrap Your Own Latent: A New Approach to S...   \n",
       "14  Unsupervised Learning of Visual Features by Co...   \n",
       "15  Why Should I Trust You?: Explaining the Predic...   \n",
       "16  A Unified Approach to Interpreting Model Predi...   \n",
       "17  Interpretability Beyond Feature Attribution: Q...   \n",
       "18  Deep Learning for Case-Based Reasoning through...   \n",
       "19  This Looks Like That: Deep Learning for Interp...   \n",
       "20  Improving language understanding by generative...   \n",
       "21      Large language models are zero-shot reasoners   \n",
       "22  Learning transferable visual models from natur...   \n",
       "23           Denoising diffusion probabilistic models   \n",
       "24  Instructpix2pix: Learning to follow image edit...   \n",
       "\n",
       "                                        Unused Papers  \n",
       "0   Attribute-based classification for zero-shot v...  \n",
       "1      Latent embeddings for zero-shot classification  \n",
       "2         Semantic Autoencoder for Zero-Shot Learning  \n",
       "3   Feature Generating Networks for Zero-Shot Lear...  \n",
       "4   Unpaired image-to-image translation using cycl...  \n",
       "5   Progressive Growing of GANs for Improved Quali...  \n",
       "6   Stargan: Unified generative adversarial networ...  \n",
       "7   Towards k-means-friendly spaces: Simultaneous ...  \n",
       "8   Spectralnet: Spectral clustering using deep ne...  \n",
       "9   Grad-cam: Visual explanations from deep networ...  \n",
       "10  Anchors: High-Precision Model-Agnostic Explana...  \n",
       "11  Bert: Pre-training of deep bidirectional trans...  \n",
       "12  Prefix-tuning: Optimizing continuous prompts f...  \n",
       "13  Lora: Low-rank adaptation of large language mo...  \n",
       "14  An Image is Worth 16x16 Words: Transformers fo...  \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "21                                                     \n",
       "22                                                     \n",
       "23                                                     \n",
       "24                                                     "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to the subfolder for downloaded PDFs\n",
    "subfolder_path = '/Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs'\n",
    "\n",
    "used_papers = []\n",
    "unused_papers = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in paper_df.iterrows():\n",
    "    paper_name = row['Paper Name']\n",
    "    found = False  # Flag to track if the paper name was found\n",
    "\n",
    "    # Iterate through all PDF files in the subfolder\n",
    "    for pdf_file in os.listdir(subfolder_path):\n",
    "        if pdf_file.endswith('.pdf'):\n",
    "            pdf_file_path = os.path.join(subfolder_path, pdf_file)\n",
    "            # print(pdf_file_path)\n",
    "            from PyPDF2 import PdfReader\n",
    "\n",
    "            # Read the PDF file\n",
    "            with open(pdf_file_path, 'rb') as file:\n",
    "                reader = PdfReader(file)\n",
    "                # Get the text from the first page\n",
    "                first_page_text = reader.pages[0].extract_text()\n",
    "\n",
    "            # Check if the paper name is in the first page text\n",
    "            if len(paper_name.split()) > 3:\n",
    "                title_words = paper_name.split()\n",
    "                match_count = sum(1 for word in title_words if word in first_page_text)\n",
    "                if match_count / len(title_words) >= 0.8:\n",
    "                    used_papers.append(paper_name)\n",
    "                    found = True\n",
    "                    new_file_path = os.path.join(subfolder_path, paper_name + '.pdf')\n",
    "                    os.rename(pdf_file_path, new_file_path)\n",
    "                    print(f\"Renamed {pdf_file_path} to {new_file_path}.\")\n",
    "                    break  # Exit the loop once the paper is found\n",
    "            else:\n",
    "                if all(word in first_page_text for word in paper_name.split()):\n",
    "                    used_papers.append(paper_name)\n",
    "                    found = True\n",
    "                    new_file_path = os.path.join(subfolder_path, paper_name + '.pdf')\n",
    "                    os.rename(pdf_file_path, new_file_path)\n",
    "                    print(f\"Renamed {pdf_file_path} to {new_file_path}.\")\n",
    "                    break  # Exit the loop once the paper is found\n",
    "\n",
    "    if not found:\n",
    "        unused_papers.append(paper_name)\n",
    "\n",
    "# Create a DataFrame to show used vs unused papers\n",
    "# Determine the maximum length between used_papers and unused_papers\n",
    "max_length = max(len(used_papers), len(unused_papers))\n",
    "\n",
    "# Extend both lists to the maximum length by adding empty strings\n",
    "used_papers.extend([''] * (max_length - len(used_papers)))\n",
    "unused_papers.extend([''] * (max_length - len(unused_papers)))\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Used Papers': used_papers,\n",
    "    'Unused Papers': unused_papers\n",
    "})\n",
    "\n",
    "# Display the summary DataFrame\n",
    "# Check for duplicates in used and unused papers\n",
    "duplicate_used = set([paper for paper in used_papers if used_papers.count(paper) > 1])\n",
    "duplicate_unused = set([paper for paper in unused_papers if unused_papers.count(paper) > 1])\n",
    "\n",
    "# Display the summary DataFrame\n",
    "\n",
    "# Show duplicates if any\n",
    "if duplicate_used:\n",
    "    print(\"Duplicate Used Papers:\", duplicate_used)\n",
    "else:\n",
    "    print(\"No duplicate used papers found.\")\n",
    "\n",
    "if duplicate_unused:\n",
    "    print(\"Duplicate Unused Papers:\", duplicate_unused)\n",
    "else:\n",
    "    print(\"No duplicate unused papers found.\")\n",
    "\n",
    "summary_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages across all PDFs: 658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CyCADA: Cycle-Consistent Adversarial Domain Ad...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Unified Approach to Interpreting Model Predi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERTopic: Neural topic modeling with a class-b...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010.11929v2.pdf</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610.02391v4.pdf</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Learning transferable visual models from natur...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Improving language understanding by generative...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Matching Networks for One Shot Learning.pdf</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Instructpix2pix: Learning to follow image edit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2106.09685v2.pdf</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Momentum Contrast for Unsupervised Visual Repr...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unsupervised Visual Domain Adaptation Using Su...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1801.01587v6.pdf</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2101.00190v1.pdf</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Learning to Compare: Relation Network for Few-...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Learning without Forgetting.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A style-based generator architecture for gener...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1606.09282v3.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unsupervised Learning of Visual Features by Co...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1812.04948v3.pdf</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1810.04805v2.pdf</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1611.07004v3.pdf</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Denoising diffusion probabilistic models.pdf</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1710.10196v3-2.pdf</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1703.05175v2.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Model-Agnostic Meta-Learning for Fast Adaptati...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Interpretability Beyond Feature Attribution: Q...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1703.10593v7.pdf</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Large language models are zero-shot reasoners.pdf</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1610.04794v2.pdf</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Unsupervised deep embedding for clustering ana...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Image-to-image translation with conditional ad...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Deep Learning for Case-Based Reasoning through...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Why Should I Trust You?: Explaining the Predic...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A Simple Framework for Contrastive Learning of...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bootstrap Your Own Latent: A New Approach to S...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>This Looks Like That: Deep Learning for Interp...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PDF Name  Number of Pages\n",
       "0   CyCADA: Cycle-Consistent Adversarial Domain Ad...               15\n",
       "1   A Unified Approach to Interpreting Model Predi...               10\n",
       "2   BERTopic: Neural topic modeling with a class-b...               10\n",
       "3                                    2010.11929v2.pdf               22\n",
       "4                                    1610.02391v4.pdf               23\n",
       "5   Learning transferable visual models from natur...               48\n",
       "6   Improving language understanding by generative...               12\n",
       "7         Matching Networks for One Shot Learning.pdf               12\n",
       "8   Instructpix2pix: Learning to follow image edit...               15\n",
       "9                                    2106.09685v2.pdf               26\n",
       "10  Momentum Contrast for Unsupervised Visual Repr...               12\n",
       "11  Unsupervised Visual Domain Adaptation Using Su...                8\n",
       "12                                   1801.01587v6.pdf               21\n",
       "13                                   2101.00190v1.pdf               15\n",
       "14  Learning to Compare: Relation Network for Few-...               10\n",
       "15                    Learning without Forgetting.pdf               13\n",
       "16  A style-based generator architecture for gener...               15\n",
       "17                                   1606.09282v3.pdf               13\n",
       "18  Unsupervised Learning of Visual Features by Co...               23\n",
       "19                                   1812.04948v3.pdf               12\n",
       "20                                   1810.04805v2.pdf               16\n",
       "21                                   1611.07004v3.pdf               17\n",
       "22       Denoising diffusion probabilistic models.pdf               25\n",
       "23                                 1710.10196v3-2.pdf               26\n",
       "24                                   1703.05175v2.pdf               13\n",
       "25  Model-Agnostic Meta-Learning for Fast Adaptati...               13\n",
       "26  Interpretability Beyond Feature Attribution: Q...               18\n",
       "27                                   1703.10593v7.pdf               18\n",
       "28  Large language models are zero-shot reasoners.pdf               42\n",
       "29                                   1610.04794v2.pdf               14\n",
       "30  Unsupervised deep embedding for clustering ana...               10\n",
       "31  Image-to-image translation with conditional ad...               26\n",
       "32  Deep Learning for Case-Based Reasoning through...                8\n",
       "33  Why Should I Trust You?: Explaining the Predic...               10\n",
       "34  A Simple Framework for Contrastive Learning of...               20\n",
       "35  Bootstrap Your Own Latent: A New Approach to S...               35\n",
       "36  This Looks Like That: Deep Learning for Interp...               12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Initialize a list to store PDF names and their lengths\n",
    "pdf_info = []\n",
    "\n",
    "# Iterate through each PDF file in the subfolder\n",
    "for filename in os.listdir(subfolder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(subfolder_path, filename)\n",
    "        \n",
    "        # Open the PDF file and count the number of pages\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "            num_pages = len(reader.pages)\n",
    "            pdf_info.append((filename, num_pages))\n",
    "\n",
    "# Calculate the total number of pages\n",
    "total_pages = sum(num_pages for _, num_pages in pdf_info)\n",
    "\n",
    "# Print the total number of pages\n",
    "print(f\"Total number of pages across all PDFs: {total_pages}\")\n",
    "\n",
    "# Create a DataFrame to display the PDF names and their lengths\n",
    "pdf_summary_df = pd.DataFrame(pdf_info, columns=['PDF Name', 'Number of Pages'])\n",
    "\n",
    "# Display the PDF summary DataFrame\n",
    "pdf_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Used Papers</th>\n",
       "      <th>Unused Papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matching Networks for One Shot Learning</td>\n",
       "      <td>Attribute-based classification for zero-shot v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model-Agnostic Meta-Learning for Fast Adaptati...</td>\n",
       "      <td>Latent embeddings for zero-shot classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning to Compare: Relation Network for Few-...</td>\n",
       "      <td>Semantic Autoencoder for Zero-Shot Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERTopic: Neural topic modeling with a class-b...</td>\n",
       "      <td>Feature Generating Networks for Zero-Shot Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning without Forgetting</td>\n",
       "      <td>Prototypical networks for few-shot learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unsupervised Visual Domain Adaptation Using Su...</td>\n",
       "      <td>Image-to-image translation with conditional ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Simple Framework for Contrastive Learning of...</td>\n",
       "      <td>Unpaired image-to-image translation using cycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Momentum Contrast for Unsupervised Visual Repr...</td>\n",
       "      <td>A style-based generator architecture for gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Progressive Growing of GANs for Improved Quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Stargan: Unified generative adversarial networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>Unsupervised deep embedding for clustering ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>Towards k-means-friendly spaces: Simultaneous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>Spectralnet: Spectral clustering using deep ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>CyCADA: Cycle-Consistent Adversarial Domain Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>Bootstrap Your Own Latent: A New Approach to S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>Unsupervised Learning of Visual Features by Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>Why Should I Trust You?: Explaining the Predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>A Unified Approach to Interpreting Model Predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>Grad-cam: Visual explanations from deep networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>Interpretability Beyond Feature Attribution: Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>Deep Learning for Case-Based Reasoning through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>This Looks Like That: Deep Learning for Interp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>Anchors: High-Precision Model-Agnostic Explana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>Bert: Pre-training of deep bidirectional trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>Improving language understanding by generative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>Prefix-tuning: Optimizing continuous prompts f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>Lora: Low-rank adaptation of large language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>Large language models are zero-shot reasoners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>An Image is Worth 16x16 Words: Transformers fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>Learning transferable visual models from natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>Denoising diffusion probabilistic models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>Instructpix2pix: Learning to follow image edit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Used Papers  \\\n",
       "0             Matching Networks for One Shot Learning   \n",
       "1   Model-Agnostic Meta-Learning for Fast Adaptati...   \n",
       "2   Learning to Compare: Relation Network for Few-...   \n",
       "3   BERTopic: Neural topic modeling with a class-b...   \n",
       "4                         Learning without Forgetting   \n",
       "5   Unsupervised Visual Domain Adaptation Using Su...   \n",
       "6   A Simple Framework for Contrastive Learning of...   \n",
       "7   Momentum Contrast for Unsupervised Visual Repr...   \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                                      \n",
       "30                                                      \n",
       "31                                                      \n",
       "\n",
       "                                        Unused Papers  \n",
       "0   Attribute-based classification for zero-shot v...  \n",
       "1      Latent embeddings for zero-shot classification  \n",
       "2         Semantic Autoencoder for Zero-Shot Learning  \n",
       "3   Feature Generating Networks for Zero-Shot Lear...  \n",
       "4         Prototypical networks for few-shot learning  \n",
       "5   Image-to-image translation with conditional ad...  \n",
       "6   Unpaired image-to-image translation using cycl...  \n",
       "7   A style-based generator architecture for gener...  \n",
       "8   Progressive Growing of GANs for Improved Quali...  \n",
       "9   Stargan: Unified generative adversarial networ...  \n",
       "10  Unsupervised deep embedding for clustering ana...  \n",
       "11  Towards k-means-friendly spaces: Simultaneous ...  \n",
       "12  Spectralnet: Spectral clustering using deep ne...  \n",
       "13  CyCADA: Cycle-Consistent Adversarial Domain Ad...  \n",
       "14  Bootstrap Your Own Latent: A New Approach to S...  \n",
       "15  Unsupervised Learning of Visual Features by Co...  \n",
       "16  Why Should I Trust You?: Explaining the Predic...  \n",
       "17  A Unified Approach to Interpreting Model Predi...  \n",
       "18  Grad-cam: Visual explanations from deep networ...  \n",
       "19  Interpretability Beyond Feature Attribution: Q...  \n",
       "20  Deep Learning for Case-Based Reasoning through...  \n",
       "21  This Looks Like That: Deep Learning for Interp...  \n",
       "22  Anchors: High-Precision Model-Agnostic Explana...  \n",
       "23  Bert: Pre-training of deep bidirectional trans...  \n",
       "24  Improving language understanding by generative...  \n",
       "25  Prefix-tuning: Optimizing continuous prompts f...  \n",
       "26  Lora: Low-rank adaptation of large language mo...  \n",
       "27      Large language models are zero-shot reasoners  \n",
       "28  An Image is Worth 16x16 Words: Transformers fo...  \n",
       "29  Learning transferable visual models from natur...  \n",
       "30           Denoising diffusion probabilistic models  \n",
       "31  Instructpix2pix: Learning to follow image edit...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize the Selenium WebDriver for Safari\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Navigate to the arXiv website\n",
    "driver.get(\"https://arxiv.org\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, wait for the page to load and check for a specific element\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.title')))\n",
    "    print(\"Successfully navigated to arXiv.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error navigating to arXiv: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "No PDF link found for Attribute-based classification for zero-shot visual object categorization.\n",
      "None\n",
      "No PDF link found for Latent embeddings for zero-shot classification.\n",
      "None\n",
      "No PDF link found for Semantic Autoencoder for Zero-Shot Learning.\n",
      "None\n",
      "No PDF link found for Feature Generating Networks for Zero-Shot Learning.\n",
      "None\n",
      "No PDF link found for Prototypical networks for few-shot learning.\n",
      "None\n",
      "No PDF link found for Matching Networks for One Shot Learning.\n",
      "None\n",
      "No PDF link found for Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.\n",
      "None\n",
      "No PDF link found for Learning to Compare: Relation Network for Few-Shot Learning.\n",
      "None\n",
      "No PDF link found for Image-to-image translation with conditional adversarial networks.\n",
      "None\n",
      "No PDF link found for Unpaired image-to-image translation using cycle-consistent adversarial networks.\n",
      "None\n",
      "No PDF link found for A style-based generator architecture for generative adversarial networks.\n",
      "None\n",
      "No PDF link found for Progressive Growing of GANs for Improved Quality, Stability, and Variation.\n",
      "No papers found for Stargan: Unified generative adversarial networks for multi-domain image-to-image translation.\n",
      "None\n",
      "No PDF link found for Unsupervised deep embedding for clustering analysis.\n",
      "None\n",
      "No PDF link found for Towards k-means-friendly spaces: Simultaneous deep learning and clustering.\n",
      "No papers found for BERTopic: Neural topic modeling with a class-based TF-IDF procedure.\n",
      "No papers found for Spectralnet: Spectral clustering using deep neural networks.\n",
      "None\n",
      "No PDF link found for Learning without Forgetting.\n",
      "None\n",
      "No PDF link found for Unsupervised Visual Domain Adaptation Using Subspace Alignment.\n",
      "No papers found for CyCADA: Cycle-Consistent Adversarial Domain Adaptation.\n",
      "None\n",
      "No PDF link found for A Simple Framework for Contrastive Learning of Visual Representations.\n",
      "None\n",
      "No PDF link found for Momentum Contrast for Unsupervised Visual Representation Learning.\n",
      "None\n",
      "No PDF link found for Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Specify the path to the subfolder for downloaded PDFs\n",
    "subfolder_path = '/Users/Sloan/Desktop/Project_Desktop/School/5.2/ML Papers/PDFs'\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "if not os.path.exists(subfolder_path):\n",
    "    os.makedirs(subfolder_path)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in paper_df.iterrows():\n",
    "    paper_name = row['Paper Name']\n",
    "    # Construct the arXiv API URL for the paper\n",
    "    api_url = f\"http://export.arxiv.org/api/query?search_query=title:{paper_name.replace(' ', '+')}&start=0&max_results=1\"\n",
    "    # print(api_url)\n",
    "    # Make a request to the arXiv API\n",
    "    response = requests.get(api_url)\n",
    "    # print(response.text)\n",
    "    if response.status_code == 200:\n",
    "        # # Check if any entries were returned\n",
    "        # if '<entry>' not in response.text:\n",
    "        #     print(f\"No papers found for {paper_name}.\")\n",
    "        #     continue\n",
    "        \n",
    "        # Parse the response to find the PDF link\n",
    "        pdf_link = None\n",
    "        if '<link rel=\"alternate\"' in response.text:\n",
    "            start_index = response.text.index('<link rel=\"alternate\"') + len('<link rel=\"alternate\" href=\"')\n",
    "            end_index = response.text.index('\"', start_index)\n",
    "            pdf_link = response.text[start_index:end_index]\n",
    "        \n",
    "        print(pdf_link)\n",
    "        if pdf_link:\n",
    "            # Extract the filename from the PDF link\n",
    "            filename = f\"{paper_name}.pdf\"\n",
    "            save_path = os.path.join(subfolder_path, filename)\n",
    "            \n",
    "            # Download the PDF file\n",
    "            pdf_response = requests.get(pdf_link)\n",
    "            if pdf_response.status_code == 200:\n",
    "                with open(save_path, \"wb\") as file:\n",
    "                    file.write(pdf_response.content)\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download PDF for {paper_name}. Status code: {pdf_response.status_code}\")\n",
    "        else:\n",
    "            print(f\"No PDF link found for {paper_name}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {paper_name}. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "download_pdfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
